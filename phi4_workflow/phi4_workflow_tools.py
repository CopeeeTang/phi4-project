import base64
import json
import torch
from PIL import Image
import io
import re
from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Circle

class ToolManager:
    """å·¥å…·ç®¡ç†ç±»ï¼Œå¤„ç†å·¥å…·å®šä¹‰ã€è°ƒç”¨å’Œç»“æœå¤„ç†"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨"""
        self.tools = self._define_tools()
        
    def _define_tools(self):
        """å®šä¹‰å¯ç”¨çš„å·¥å…·åˆ—è¡¨"""
        tools = [
            {
                "name": "crop_image_at_gaze",
                "description": "æ ¹æ®æ³¨è§†åæ ‡å’ŒåŠå¾„è£å‰ªå›¾åƒçš„ç‰¹å®šåŒºåŸŸï¼Œå¹¶å¯é€‰æ‹©è¿›è¡Œå›¾åƒé¢„å¤„ç†",
                "parameters": {
                    "properties": {
                        "image_base64": {
                            "title": "Image Base64",
                            "type": "string"
                        },
                        "coordinates": {
                            "additionalProperties": {
                                "type": "number"
                            },
                            "title": "Coordinates",
                            "type": "object"
                        },
                        "radius": {
                            "default": 0.05,
                            "title": "Radius",
                            "type": "number"
                        },
                        "crop_size": {
                            "anyOf": [
                                {
                                    "additionalProperties": {
                                        "type": "integer"
                                    },
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Crop Size"
                        },
                        "apply_preprocessing": {
                            "default": True,
                            "title": "Apply Preprocessing",
                            "type": "boolean"
                        },
                        "preprocessing_options": {
                            "anyOf": [
                                {
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Preprocessing Options"
                        }
                    },
                    "required": [
                        "image_base64",
                        "coordinates"
                    ],
                }
            },
            {
                "name": "analyze_gaze_region",
                "description": "åˆ†æç”¨æˆ·æ³¨è§†çš„åŒºåŸŸï¼Œå¹¶è¯†åˆ«é¡µé¢å¯èƒ½çš„åŠŸèƒ½",
                "parameters": {
                    "properties": {
                        "image_base64": {
                            "title": "Image Base64",
                            "type": "string"
                        },
                        "coordinates": {
                            "additionalProperties": {
                                "type": "number"
                            },
                            "title": "Coordinates",
                            "type": "object"
                        },
                        "page_context": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Page Context"
                        }
                    },
                    "required": [
                        "image_base64",
                        "coordinates"
                    ]
                }
            },
            {
                "name": "interpret_gaze_intent",
                "description": "è§£é‡Šç”¨æˆ·çš„æ³¨è§†æ„å›¾",
                "parameters": {
                    "properties": {
                        "coordinates": {
                            "additionalProperties": {
                                "type": "number"
                            },
                            "title": "Coordinates",
                            "type": "object"
                        },
                        "screen_area": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Screen Area"
                        },
                        "page_context": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Page Context"
                        },
                        "region_analysis": {
                            "anyOf": [
                                {
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Region Analysis"
                        }
                    },
                    "required": [
                        "coordinates"
                    ]
                }
            },
            {
                "name": "interpret_gesture_intent",
                "description": "è§£é‡Šæ‰‹åŠ¿æ„å›¾ï¼Œç»“åˆé¡µé¢ä¸Šä¸‹æ–‡å’Œçœ¼åŠ¨æ•°æ®è¿›è¡Œç†è§£",
                "parameters": {
                    "properties": {
                        "gesture_name": {
                            "title": "Gesture Name",
                            "type": "string"
                        },
                        "confidence": {
                            "title": "Confidence",
                            "type": "number"
                        },
                        "page_context": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Page Context"
                        },
                        "context_info": {
                            "anyOf": [
                                {
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Context Info"
                        },
                        "gaze_data": {
                            "anyOf": [
                                {
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Gaze Data"
                        }
                    },
                    "required": [
                        "gesture_name",
                        "confidence"
                    ]
                }
            },
            {
                "name": "map_gesture_to_action",
                "description": "å°†æ‰‹åŠ¿æ˜ å°„åˆ°åº”ç”¨ç¨‹åºæ“ä½œ",
                "parameters": {
                    "properties": {
                        "gesture_name": {
                            "title": "Gesture Name",
                            "type": "string"
                        },
                        "application_context": {
                            "default": "general",
                            "title": "Application Context",
                            "type": "string"
                        },
                        "intent": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Intent"
                        },
                        "ui_elements": {
                            "anyOf": [
                                {
                                    "items": {
                                        "type": "string"
                                    },
                                    "type": "array"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Ui Elements"
                        }
                    },
                    "required": [
                        "gesture_name"
                    ]
                }
            },
            {
                "name": "get_ui_element_at_position",
                "description": "è·å–å±å¹•ç‰¹å®šä½ç½®çš„UIå…ƒç´ ä¿¡æ¯",
                "parameters": {
                    "properties": {
                        "image_base64": {
                            "title": "Image Base64",
                            "type": "string"
                        },
                        "coordinates": {
                            "additionalProperties": {
                                "type": "number"
                            },
                            "title": "Coordinates",
                            "type": "object"
                        },
                        "element_type": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Element Type"
                        }
                    },
                    "required": [
                        "image_base64",
                        "coordinates"
                    ]
                }
            },
            {
                "name": "generate_ui_action",
                "description": "ç”Ÿæˆç”¨æˆ·ç•Œé¢æ“ä½œæŒ‡ä»¤",
                "parameters": {
                    "properties": {
                        "intent": {
                            "title": "Intent",
                            "type": "string"
                        },
                        "ui_element": {
                            "anyOf": [
                                {
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Ui Element"
                        },
                        "action_type": {
                            "anyOf": [
                                {
                                    "type": "string"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Action Type"
                        },
                        "coordinates": {
                            "anyOf": [
                                {
                                    "additionalProperties": {
                                        "type": "number"
                                    },
                                    "type": "object"
                                },
                                {
                                    "type": "null"
                                }
                            ],
                            "default": None,
                            "title": "Coordinates"
                        }
                    },
                    "required": [
                        "intent"
                    ]
                }
            }
        ]
        return tools
    
    def get_tools_json(self):
        """è¿”å›å·¥å…·çš„JSONè¡¨ç¤º"""
        return json.dumps(self.tools)
    
    def parse_tool_calls(self, response):
        """ä»å“åº”ä¸­è§£æå·¥å…·è°ƒç”¨"""
        tool_call_pattern = r'```tool_call\n(.*?)\n```'
        matches = re.finditer(tool_call_pattern, response, re.DOTALL)
        tool_calls = []
        
        for match in matches:
            try:
                tool_call_json = json.loads(match.group(1))
                tool_calls.append(tool_call_json)
            except json.JSONDecodeError:
                print(f"æ— æ³•è§£æå·¥å…·è°ƒç”¨JSON: {match.group(1)}")
        
        return tool_calls


class Phi4WorkflowWithTools:
    def __init__(self, model_path="/home/lab/phi4/phi4"):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_path, 
            device_map="cuda", 
            torch_dtype="auto", 
            trust_remote_code=True,
            _attn_implementation='flash_attention_2',
        ).cuda()
        self.tool_manager = ToolManager()
        self.results = {}  # å­˜å‚¨å·¥ä½œæµå„æ­¥éª¤çš„ç»“æœ
    
    def _encode_image_to_base64(self, image):
        """å°†PILå›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode("utf-8")
    
    def _decode_base64_to_image(self, base64_string):
        """å°†base64å­—ç¬¦ä¸²è§£ç ä¸ºPILå›¾åƒ"""
        return Image.open(io.BytesIO(base64.b64decode(base64_string)))
    
    def _call_phi4_with_tools(self, prompt, images=None, audios=None):
        """ä½¿ç”¨Phi-4å¤„ç†å¸¦å·¥å…·çš„æç¤ºè¯"""
        # åŒ…å«toolså‚æ•°
        prompt_with_tools = prompt + f"\n\nTools:\n{self.tool_manager.get_tools_json()}"
        
        inputs = self.processor(
            text=prompt_with_tools,
            images=images,
            return_tensors='pt'
        ).to('cuda:0')
        
        generation_config = GenerationConfig.from_pretrained("microsoft/Phi-4-multimodal-instruct")
        
        generate_ids = self.model.generate(
            **inputs,
            max_new_tokens=1024,
            generation_config=generation_config,
        )
        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]
        
        response = self.processor.batch_decode(
            generate_ids,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        return response
    
    def _call_phi4_without_tools(self, prompt, images=None, audios=None):
        """ä½¿ç”¨Phi-4å¤„ç†ä¸å¸¦å·¥å…·çš„æç¤ºè¯ï¼ˆæ ‡å‡†æ¨ç†ï¼‰"""
        inputs = self.processor(
            text=prompt,
            images=images,
            return_tensors='pt'
        ).to('cuda:0')
        
        generation_config = GenerationConfig.from_pretrained("microsoft/Phi-4-multimodal-instruct")
        
        generate_ids = self.model.generate(
            **inputs,
            max_new_tokens=512,
            generation_config=generation_config,
        )
        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]
        
        response = self.processor.batch_decode(
            generate_ids,
            skip_special_tokens=True,
            clean_up_tokenization_spaces=False
        )[0]
        
        return response
    
    def step1_raw_input_processing(self, gesture_name="pinch", gaze_data={"x": 0.4, "y": 0.5, "r": 0.1}, screenshot=None):
        """æ­¥éª¤1: å¤„ç†åŸå§‹è¾“å…¥ï¼Œå‡†å¤‡åœºæ™¯åˆ†æ"""
        
        # æ ¼å¼åŒ–è¾“å…¥
        formatted_input = {
            "gesture": {
                "name": gesture_name,
                "confidence": 0.95  # å‡è®¾ç½®ä¿¡åº¦
            },
            "gaze": {
                "x": gaze_data["x"],
                "y": gaze_data["y"],
                "radius": gaze_data.get("r", 0.1)
            },
            "screenshot": screenshot
        }
        
        # å­˜å‚¨ç»“æœ
        self.results["step1_input"] = formatted_input
        
        # ç¼–ç å›¾åƒä¸ºbase64ï¼ˆå¦‚æœæœ‰ï¼‰
        if screenshot:
            formatted_input["screenshot_base64"] = self._encode_image_to_base64(screenshot)
        
        return formatted_input
    
    def step2_page_function_extraction(self, input_data):
        """æ­¥éª¤2: é¡µé¢åŠŸèƒ½æå–ï¼Œç†è§£å½“å‰UIçš„åŠŸèƒ½å’Œå…ƒç´ """
        
        screenshot = input_data.get("screenshot")
        if not screenshot:
            return {"error": "æ²¡æœ‰æä¾›æˆªå›¾ï¼Œæ— æ³•åˆ†æé¡µé¢"}
        
        # æ„å»ºæç¤ºè¯
        prompt = """<|user|><|image_1|>
        ä½ æ˜¯ä¸€ä¸ªå›¾åƒUIåˆ†æåŠ©æ‰‹ï¼Œè¯·åˆ†æå½“å‰å±å¹•ä¸Šæ˜¾ç¤ºçš„ç•Œé¢ã€‚
        1. é¦–å…ˆï¼Œç”¨ä¸€åˆ°ä¸¤å¥è¯æ¦‚æ‹¬è¿™ä¸ªç•Œé¢çš„ä¸»è¦åŠŸèƒ½å’Œç±»å‹
        2. åˆ—å‡ºç•Œé¢ä¸Šçš„ä¸»è¦å…ƒç´ å’Œå®ƒä»¬çš„åŠŸèƒ½
        3. ç¡®å®šè¿™æ˜¯ä»€ä¹ˆåº”ç”¨æˆ–ç½‘ç«™
        <|end|>
        <|assistant|>"""
        
        # è°ƒç”¨Phi4è¿›è¡Œåˆ†æ
        response = self._call_phi4_without_tools(prompt, images=screenshot)
        
        # è§£æç»“æœ
        analysis = {
            "raw_analysis": response,
            "page_type": None,  # é€šè¿‡åå¤„ç†æå–
            "ui_elements": [],  # é€šè¿‡åå¤„ç†æå–
            "application": None # é€šè¿‡åå¤„ç†æå–
        }
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ åå¤„ç†é€»è¾‘ï¼Œä»responseæå–ç»“æ„åŒ–ä¿¡æ¯
        # ...
        
        # å­˜å‚¨ç»“æœ
        self.results["step2_page_analysis"] = analysis
        
        return analysis
    
    def step3_intent_recognition(self, input_data, scene_analysis):
        """æ­¥éª¤3: æ„å›¾è¯†åˆ«ï¼Œç†è§£ç”¨æˆ·æƒ³è¦åšä»€ä¹ˆ"""
        
        gesture = input_data.get("gesture", {})
        gaze = input_data.get("gaze", {})
        screenshot = input_data.get("screenshot")
        
        if not screenshot:
            return {"error": "æ²¡æœ‰æä¾›æˆªå›¾ï¼Œæ— æ³•åˆ†ææ„å›¾"}
        
        # æ„å»ºæç¤ºè¯ï¼Œä½¿ç”¨å·¥å…·è°ƒç”¨è¿›è¡Œæ›´ç²¾ç¡®çš„åˆ†æ
        prompt = f"""<|user|><|image_1|>
        ä½ æ˜¯ä¸€ä¸ªæ··åˆæ¨¡æ€ç”¨æˆ·æ„å›¾åˆ†æå¸ˆã€‚è¯·ç”¨ä»¥ä¸‹ä¿¡æ¯ç†è§£ç”¨æˆ·æ„å›¾ï¼š

        ç”¨æˆ·å½“å‰ç•Œé¢ä¿¡æ¯ï¼š
        {scene_analysis.get("raw_analysis", "æœªæä¾›ç•Œé¢åˆ†æ")}

        ç”¨æˆ·æ‰‹åŠ¿ï¼š{gesture.get("name", "æœªçŸ¥")}
        æ‰‹åŠ¿ç½®ä¿¡åº¦ï¼š{gesture.get("confidence", 0.0)}

        ç”¨æˆ·è§†çº¿ä½ç½®ï¼š
        - Xåæ ‡ï¼š{gaze.get("x", 0.0)}ï¼ˆèŒƒå›´0-1ï¼Œ0æ˜¯å·¦è¾¹ç¼˜ï¼Œ1æ˜¯å³è¾¹ç¼˜ï¼‰
        - Yåæ ‡ï¼š{gaze.get("y", 0.0)}ï¼ˆèŒƒå›´0-1ï¼Œ0æ˜¯ä¸Šè¾¹ç¼˜ï¼Œ1æ˜¯ä¸‹è¾¹ç¼˜ï¼‰

        è¯·é€šè¿‡è°ƒç”¨åˆé€‚çš„å·¥å…·ï¼Œåˆ†æç”¨æˆ·çš„æ„å›¾å’Œå¯èƒ½æƒ³è¦æ‰§è¡Œçš„æ“ä½œã€‚

        é¦–å…ˆï¼Œæ ¹æ®ç”¨æˆ·çš„è§†çº¿ä½ç½®åˆ†æå…¶æ­£åœ¨å…³æ³¨çš„åŒºåŸŸã€‚
        ç„¶åï¼Œç»“åˆç”¨æˆ·çš„æ‰‹åŠ¿å’Œä¸Šä¸‹æ–‡ï¼Œæ¨æ–­ç”¨æˆ·çš„å®Œæ•´æ„å›¾ã€‚
        æœ€åï¼Œç”Ÿæˆä¸€ä¸ªå…·ä½“çš„UIæ“ä½œå»ºè®®ã€‚
        <|end|>
        <|assistant|>"""
        
        # è°ƒç”¨Phi4è¿›è¡Œåˆ†æï¼ˆå¸¦å·¥å…·ï¼‰
        response = self._call_phi4_with_tools(prompt, images=screenshot)
        
        # è§£æå·¥å…·è°ƒç”¨
        tool_calls = self.tool_manager.parse_tool_calls(response)
        
        # å¤„ç†ç»“æœ
        intent_analysis = {
            "raw_response": response,
            "tool_calls": tool_calls,
            "interpreted_intent": None,  # é€šè¿‡åå¤„ç†æå–
            "suggested_action": None,    # é€šè¿‡åå¤„ç†æå–
            "confidence": None           # é€šè¿‡åå¤„ç†æå–
        }
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä»å·¥å…·è°ƒç”¨å’Œå“åº”ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯çš„åå¤„ç†é€»è¾‘
        # ...
        
        # ä»å“åº”ä¸­æå–ä¸»è¦æ„å›¾ï¼ˆç®€å•ç¤ºä¾‹ï¼‰
        intent_match = re.search(r"ç”¨æˆ·æ„å›¾:(.*?)(?:\n|$)", response, re.MULTILINE | re.IGNORECASE)
        if intent_match:
            intent_analysis["interpreted_intent"] = intent_match.group(1).strip()
        
        # ä»å“åº”ä¸­æå–å»ºè®®åŠ¨ä½œï¼ˆç®€å•ç¤ºä¾‹ï¼‰
        action_match = re.search(r"å»ºè®®åŠ¨ä½œ:(.*?)(?:\n|$)", response, re.MULTILINE | re.IGNORECASE)
        if action_match:
            intent_analysis["suggested_action"] = action_match.group(1).strip()
        
        # å­˜å‚¨ç»“æœ
        self.results["step3_intent_analysis"] = intent_analysis
        
        return intent_analysis
    
    def visualize_gaze_on_screenshot(self, screenshot, gaze_data):
        """åœ¨æˆªå›¾ä¸Šå¯è§†åŒ–çœ¼åŠ¨ç‚¹"""
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.imshow(screenshot)
        
        # è·å–å›¾åƒå°ºå¯¸
        width, height = screenshot.size
        
        # è½¬æ¢ç›¸å¯¹åæ ‡ä¸ºåƒç´ åæ ‡
        x_pixel = gaze_data["x"] * width
        y_pixel = gaze_data["y"] * height
        
        # è®¡ç®—åœ†çš„åŠå¾„ï¼ˆç›¸å¯¹å€¼è½¬ä¸ºåƒç´ å€¼ï¼‰
        radius_pixel = gaze_data.get("radius", 0.05) * min(width, height)
        
        # æ·»åŠ è¡¨ç¤ºè§†çº¿çš„åœ†åœˆ
        gaze_circle = Circle((x_pixel, y_pixel), radius_pixel, 
                             color='red', alpha=0.5, fill=True)
        ax.add_patch(gaze_circle)
        
        # æ·»åŠ è§†çº¿åæ ‡ç‚¹
        ax.plot(x_pixel, y_pixel, 'ro', markersize=5)
        
        # æ·»åŠ åæ ‡æ ‡ç­¾
        ax.text(x_pixel + 10, y_pixel + 10, 
                f"({gaze_data['x']:.2f}, {gaze_data['y']:.2f})", 
                color='white', fontsize=12, 
                bbox=dict(facecolor='black', alpha=0.7))
        
        # å…³é—­åæ ‡è½´
        ax.axis('off')
        
        return fig
    
    def visualize_results(self):
        """å¯è§†åŒ–å·¥ä½œæµç»“æœ"""
        if not self.results:
            print("æ²¡æœ‰å¯è§†åŒ–çš„ç»“æœ")
            return None
        
        # è·å–è¾“å…¥æ•°æ®
        input_data = self.results.get("step1_input", {})
        screenshot = input_data.get("screenshot")
        gaze_data = input_data.get("gaze", {})
        gesture = input_data.get("gesture", {})
        
        # è·å–åˆ†æç»“æœ
        page_analysis = self.results.get("step2_page_analysis", {})
        intent_analysis = self.results.get("step3_intent_analysis", {})
        
        if not screenshot:
            print("æ²¡æœ‰æˆªå›¾ï¼Œæ— æ³•å¯è§†åŒ–")
            return None
        
        # åˆ›å»ºå¯è§†åŒ–
        fig, ax = plt.subplots(figsize=(12, 8))
        ax.imshow(screenshot)
        
        # è·å–å›¾åƒå°ºå¯¸
        width, height = screenshot.size
        
        # è½¬æ¢ç›¸å¯¹åæ ‡ä¸ºåƒç´ åæ ‡
        x_pixel = gaze_data.get("x", 0.5) * width
        y_pixel = gaze_data.get("y", 0.5) * height
        
        # è®¡ç®—åœ†çš„åŠå¾„ï¼ˆç›¸å¯¹å€¼è½¬ä¸ºåƒç´ å€¼ï¼‰
        radius_pixel = gaze_data.get("radius", 0.05) * min(width, height)
        
        # æ·»åŠ è¡¨ç¤ºè§†çº¿çš„åœ†åœˆ
        gaze_circle = Circle((x_pixel, y_pixel), radius_pixel, 
                             color='red', alpha=0.3, fill=True)
        ax.add_patch(gaze_circle)
        
        # æ·»åŠ è§†çº¿åæ ‡ç‚¹
        ax.plot(x_pixel, y_pixel, 'ro', markersize=8)
        
        # åœ¨å›¾åƒä¸Šæ·»åŠ åˆ†æç»“æœæ–‡æœ¬
        txt = f"æ‰‹åŠ¿: {gesture.get('name', 'æœªçŸ¥')}\n"
        txt += f"è§†çº¿ä½ç½®: ({gaze_data.get('x', 0):.2f}, {gaze_data.get('y', 0):.2f})\n\n"
        
        if intent_analysis.get("interpreted_intent"):
            txt += f"æ„å›¾: {intent_analysis['interpreted_intent']}\n"
        
        if intent_analysis.get("suggested_action"):
            txt += f"å»ºè®®æ“ä½œ: {intent_analysis['suggested_action']}\n"
        
        # æ·»åŠ æ–‡æœ¬æ¡†
        props = dict(boxstyle='round', facecolor='black', alpha=0.7)
        ax.text(0.02, 0.98, txt, transform=ax.transAxes, fontsize=12,
                verticalalignment='top', color='white', bbox=props)
        
        # å…³é—­åæ ‡è½´
        ax.axis('off')
        plt.tight_layout()
        
        return fig
    
    def run_workflow(self, gesture_name="pinch", gaze_data={"x": 0.4, "y": 0.5, "r": 0.1}, screenshot=None, visualize=True):
        """è¿è¡Œå®Œæ•´å·¥ä½œæµ"""
        print("ğŸš€ å¼€å§‹å¤šæ¨¡æ€ç”¨æˆ·æ„å›¾åˆ†æå·¥ä½œæµ")
        
        # æ­¥éª¤1: å¤„ç†åŸå§‹è¾“å…¥
        print("\nğŸ”¹ æ­¥éª¤1: å¤„ç†è¾“å…¥æ•°æ®")
        input_data = self.step1_raw_input_processing(gesture_name, gaze_data, screenshot)
        
        # æ­¥éª¤2: é¡µé¢åŠŸèƒ½æå–
        print("\nğŸ”¹ æ­¥éª¤2: åˆ†æé¡µé¢åŠŸèƒ½")
        scene_analysis = self.step2_page_function_extraction(input_data)
        
        # æ­¥éª¤3: æ„å›¾è¯†åˆ«
        print("\nğŸ”¹ æ­¥éª¤3: è¯†åˆ«ç”¨æˆ·æ„å›¾")
        intent_analysis = self.step3_intent_recognition(input_data, scene_analysis)
        
        # å¯è§†åŒ–ç»“æœ
        if visualize and screenshot:
            print("\nğŸ”¹ ç”Ÿæˆå¯è§†åŒ–ç»“æœ")
            fig = self.visualize_results()
            if fig:
                plt.show()
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        print("\nâœ… å·¥ä½œæµå®Œæˆï¼")
        print(f"é¡µé¢åˆ†æ: {scene_analysis.get('raw_analysis', '')[:100]}...")
        print(f"æ¨æ–­æ„å›¾: {intent_analysis.get('interpreted_intent', 'æœªèƒ½è¯†åˆ«æ„å›¾')}")
        if intent_analysis.get("suggested_action"):
            print(f"å»ºè®®æ“ä½œ: {intent_analysis['suggested_action']}")
        
        return {
            "page_analysis": scene_analysis,
            "intent_analysis": intent_analysis
        }


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import os
    from PIL import Image
    
    # åˆå§‹åŒ–å·¥ä½œæµ
    workflow = Phi4WorkflowWithTools()
    
    # æµ‹è¯•å›¾åƒè·¯å¾„
    test_image_path = "test_video_player.png"
    
    # å¦‚æœæµ‹è¯•å›¾åƒä¸å­˜åœ¨
    if not os.path.exists(test_image_path):
        print(f"æµ‹è¯•å›¾åƒ {test_image_path} ä¸å­˜åœ¨ï¼Œåˆ›å»ºç¤ºä¾‹å›¾åƒ")
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ
        img = Image.new('RGB', (800, 600), color=(73, 109, 137))
        img.save(test_image_path)
    
    # åŠ è½½æµ‹è¯•å›¾åƒ
    screenshot = Image.open(test_image_path)
    
    # æµ‹è¯•æ‰‹åŠ¿å’Œè§†çº¿æ•°æ®
    gesture_name = "pinch"  # æåˆæ‰‹åŠ¿
    gaze_data = {"x": 0.6, "y": 0.4, "r": 0.15}  # è§†çº¿ä½ç½®å’ŒåŠå¾„
    
    # è¿è¡Œå·¥ä½œæµ
    result = workflow.run_workflow(
        gesture_name=gesture_name,
        gaze_data=gaze_data,
        screenshot=screenshot,
        visualize=True
    )
    
    print("\nç»“æœ:", result)